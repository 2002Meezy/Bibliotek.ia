# üìö Bibliotek.IA

![Bibliotek.IA Logo](assets/bibliotek-logo.jpg)

> **O seu curador liter√°rio pessoal movido por Intelig√™ncia Artificial.**

O **Bibliotek.IA** √© uma aplica√ß√£o web inovadora que utiliza Vis√£o Computacional e LLMs (Large Language Models) para analisar fotos da sua estante de livros real e fornecer recomenda√ß√µes personalizadas, insights e gest√£o de leitura.

---

## ‚ú® Funcionalidades Principais

-   üì∑ **An√°lise Visual de Estante**: Tire uma foto dos seus livros e a IA identificar√° automaticamente os t√≠tulos e autores.
-   üîç **Recomenda√ß√µes Inteligentes**:
    -   **Modo Estrito (OFF)**: Sugere leituras baseadas *apenas* nos livros que voc√™ j√° tem na estante (redescubra sua cole√ß√£o).
    -   **Modo Descoberta (ON)**: Analisa seu gosto e sugere livros **novos** e in√©ditos que combinam com sua "vibe", garantindo que voc√™ n√£o receba recomenda√ß√µes repetidas.
-   üÜö **Cruzamento de Vibes (Compara√ß√£o)**: Selecione dois livros para ver como eles se conectam tematicamente.
-   üìö **Biblioteca Pessoal**: Gerencie seus livros (Lidos, Lendo, Quero Ler), filtre por g√™neros e veja estat√≠sticas.
-   üîê **Sistema de Contas**: Login, Registro e Perfil de Usu√°rio com persist√™ncia de dados.

---

## üõ†Ô∏è Tecnologias Utilizadas

Este projeto foi constru√≠do com uma stack moderna e robusta:

### Frontend (Aplica√ß√£o Web)
-   **[Next.js 16](https://nextjs.org/)**: Framework React para produ√ß√£o (App Router).
-   **[React 19](https://react.dev/)**: Biblioteca para constru√ß√£o de interfaces.
-   **[TypeScript](https://www.typescriptlang.org/)**: Superset JavaScript com tipagem est√°tica.
-   **[Tailwind CSS](https://tailwindcss.com/)**: Framework de estiliza√ß√£o utility-first.
-   **[Prisma ORM](https://www.prisma.io/)**: ORM moderno para Node.js e TypeScript.
-   **[bcryptjs](https://www.npmjs.com/package/bcryptjs)**: Biblioteca para hashing seguro de senhas.
-   **[Lucide React](https://lucide.dev/)**: √çcones leves e consistentes.

### Backend (Microsservi√ßo de IA)
-   **[Python 3.10+](https://www.python.org/)**: Linguagem de programa√ß√£o do backend.
-   **[FastAPI](https://fastapi.tiangolo.com/)**: Framework web moderno e de alta performance.
-   **[LangChain](https://www.langchain.com/)**: Framework para orquestra√ß√£o de LLMs.
-   **[Pydantic](https://docs.pydantic.dev/)**: Valida√ß√£o de dados robusta.

### Intelig√™ncia Artificial & Infraestrutura
-   **[LM Studio](https://lmstudio.ai/)**: Servidor de infer√™ncia local (OpenAI-compatible).
-   **Modelo de Vis√£o**: `qwen/qwen3-vl-4b` (Recomendado para an√°lise visual).
-   **Banco de Dados**: SQLite (Integrado via Prisma).

---

## üöÄ Como Executar o Projeto

Siga este guia passo a passo para rodar o Bibliotek.IA na sua m√°quina.

### Pr√©-requisitos

1.  **Node.js** (v18 ou superior) instalado.
2.  **Python** (v3.10 ou superior) instalado.
3.  **LM Studio** instalado e configurado (Instru√ß√µes abaixo).

---

### Passo 1: Configurar a IA Local (LM Studio)

1.  Baixe e instale o [LM Studio](https://lmstudio.ai/).
2.  Abra o LM Studio e baixe um modelo de vis√£o (Vision Model).
    -   *Recomendado*: **`qwen/qwen3-vl-4b`** (ou verifique o arquivo `backend/agent.py` para ver o modelo configurado).
3.  V√° para a aba de **Server** (√≠cone de "<->").
4.  Inicie o servidor local na porta **1234**.
    -   Certifique-se que a URL √© `http://localhost:1234`.
    -   Mantenha esta janela aberta.

### Passo 2: Instalar o Frontend (Next.js)

1.  Abra um terminal na pasta raiz do projeto.
2.  Instale as depend√™ncias:
    ```bash
    npm install
    ```
3.  Gere o cliente do banco de dados:
    ```bash
    npx prisma generate
    ```
4.  Crie o banco de dados local:
    ```bash
    npx prisma db push
    ```

### Passo 3: Instalar o Backend (Python)

1.  Abra um **segundo terminal** e entre na pasta `backend`:
    ```bash
    cd backend
    ```
2.  Crie um ambiente virtual (recomendado):
    ```bash
    python -m venv .venv
    ```
3.  Ative o ambiente virtual:
    -   Windows: `.venv\Scripts\activate`
    -   Mac/Linux: `source .venv/bin/activate`
4.  Instale as depend√™ncias Python:
    ```bash
    pip install -r requirements.txt
    ```
    *(Nota: Se n√£o houver `requirements.txt`, instale manualmente: `pip install fastapi uvicorn langchain-openai python-multipart`)*

### Passo 4: Configura√ß√£o de Ambiente (Opcional)

O projeto vem configurado com valores padr√£o (localhost), mas voc√™ pode criar arquivos `.env` para personalizar.

**No Backend (`backend/.env`):**
```env
LM_STUDIO_BASE_URL="http://localhost:1234/v1"
LM_STUDIO_MODEL="qwen/qwen3-vl-4b"
```

**No Frontend (`.env.local`):**
```env
NEXT_PUBLIC_BACKEND_URL="http://localhost:8000"
```

### Passo 5: Rodar a Aplica√ß√£o

Este projeto utiliza uma arquitetura de 3 partes. Voc√™ precisar√° de **3 terminais abertos**:

**Terminal 1 (Interface - Vite):**
```bash
npm run dev
```
> O Frontend rodar√° em: `http://localhost:5173` (ou 3000)

**Terminal 2 (API & Auth - Next.js):**
```bash
npx next dev -p 3001
```
> A API de autentica√ß√£o rodar√° em: `http://localhost:3001`

**Terminal 3 (C√©rebro AI - Python):**
*(Dentro da pasta backend e com venv ativado)*
```bash
python -m uvicorn main:app --reload --host 127.0.0.1 --port 8000
```
> O Backend Python rodar√° em: `http://localhost:8000`

---

## üéÆ Como Usar

1.  Acesse `http://localhost:3000` no seu navegador.
2.  Crie uma conta em "Entrar ou Criar Conta" > "Registre-se".
3.  Fa√ßa login.
4.  Na tela inicial, escolha seus g√™neros favoritos.
5.  Tire uma foto (ou fa√ßa upload) da sua estante.
6.  Clique em **"Buscar matches na estante"**.
    -   Use o bot√£o **"Descoberta" (Toggle)** para alternar entre recomenda√ß√µes da estante ou novos livros.

---

## üÜò Solu√ß√£o de Problemas Comuns

-   **Erro "Connection Refused" na an√°lise**:
    -   Verifique se o *backend Python* est√° rodando no terminal 2.
    -   Verifique se o *LM Studio* est√° rodando o servidor na porta 1234.
-   **"Failed to fetch" no Login**:
    -   Verifique se o *Next.js* est√° rodando no terminal 1.
-   **IA n√£o reconhece livros**:
    -   Certifique-se de usar um modelo de **Vis√£o** (VL) no LM Studio. Modelos apenas de texto n√£o conseguem "ver" a imagem.
